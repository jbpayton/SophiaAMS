# Sophia AMS - Docker Environment Configuration Template
# Copy this file to .env and customize for your deployment

# =============================================================================
# LLM API Configuration
# =============================================================================
# OpenAI-compatible API endpoint
# For LM Studio running on host: http://host.docker.internal:1234/v1
# For external API: https://api.openai.com/v1
# For localhost API: http://localhost:1234/v1 (change to host.docker.internal in Docker)
LLM_API_BASE=http://localhost:1234/v1
OPENAI_API_BASE=http://host.docker.internal:1234/v1

# API Key for the LLM service
# For LM Studio: Use "not-needed" or any placeholder
# For OpenAI: Use your actual API key
LLM_API_KEY=not-needed
OPENAI_API_KEY=not-needed

# Model name/identifier
LLM_MODEL=openai/gpt-oss-20b

# Optional: Different models for specific tasks
SUMMARY_MODEL=openai/gpt-oss-20b
EXTRACTION_MODEL=openai/gpt-oss-20b
VERBOSE_SUMMARY_MODEL=openai/gpt-oss-20b
EXTRACTION_MAX_TOKENS=8192
SUMMARY_MAX_TOKENS=4096

# =============================================================================
# Embedding Model Configuration
# =============================================================================
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIM=384

# =============================================================================
# Vector Database Configuration
# =============================================================================
# Qdrant URL (internal Docker network)
# Default: http://qdrant:6333 (uses Docker service name)
QDRANT_URL=http://qdrant:6333

# Legacy Milvus configuration (if needed for migration)
# MILVUS_HOST=127.0.0.1
# MILVUS_PORT=19530
# MILVUS_COLLECTION_NAME=knowledge_graph

# =============================================================================
# Search Engine Configuration
# =============================================================================
# SearXNG URL (optional)
# For SearXNG running on host: http://host.docker.internal:8088
# For localhost: http://localhost:8088
# Leave empty to disable web search functionality
SEARXNG_URL=http://localhost:8088

# =============================================================================
# Server Configuration
# =============================================================================
# Agent server port (internal)
AGENT_PORT=5001

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# Network Configuration
# =============================================================================
# These are used by the frontend to connect to the backend
# When accessing from outside Docker, use localhost
VITE_API_URL=http://localhost:3001

# =============================================================================
# Legacy Configuration
# =============================================================================
# Kept for backwards compatibility
LOCAL_TEXTGEN_API_BASE=http://localhost:5000/v1
LOCAL_TEXTGEN_API_KEY=your-api-key-here

# =============================================================================
# Optional: External Service URLs
# =============================================================================
# If you want to use external Qdrant instance instead of containerized one:
# QDRANT_URL=http://your-qdrant-server:6333

# If you want to use hosted LLM API:
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_API_KEY=sk-your-actual-api-key-here
# LLM_API_BASE=https://api.openai.com/v1
# LLM_API_KEY=sk-your-actual-api-key-here

# =============================================================================
# Development Mode Settings
# =============================================================================
# Uncomment these for development with hot-reload
# NODE_ENV=development
# PYTHONUNBUFFERED=1
# PYTHONDONTWRITEBYTECODE=1
