# Sophia AMS - Docker Environment Configuration Template
# Copy this file to .env and customize for your deployment

# =============================================================================
# LLM API Configuration
# =============================================================================
# OpenAI-compatible API endpoint
# IMPORTANT: When LLM is running on the SAME machine as Docker (localhost:1234),
#            Docker containers must use host.docker.internal instead of localhost
#
# For LM Studio/LLM running on the Docker host machine:
LLM_API_BASE=http://localhost:1234/v1
OPENAI_API_BASE=http://host.docker.internal:1234/v1

# For external API:
# LLM_API_BASE=https://api.openai.com/v1
# OPENAI_API_BASE=https://api.openai.com/v1

# API Key for the LLM service
# For local LLM (LM Studio, Ollama, etc): Use "not-needed" or any placeholder
# For OpenAI: Use your actual API key
LLM_API_KEY=not-needed
OPENAI_API_KEY=not-needed

# Model name/identifier
LLM_MODEL=openai/gpt-oss-20b

# Optional: Different models for specific tasks
SUMMARY_MODEL=openai/gpt-oss-20b
EXTRACTION_MODEL=openai/gpt-oss-20b
VERBOSE_SUMMARY_MODEL=openai/gpt-oss-20b
EXTRACTION_MAX_TOKENS=8192
SUMMARY_MAX_TOKENS=4096

# =============================================================================
# Embedding Model Configuration
# =============================================================================
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIM=384

# =============================================================================
# Vector Database Configuration
# =============================================================================
# Qdrant URL (internal Docker network)
# Default: http://qdrant:6333 (uses Docker service name)
QDRANT_URL=http://qdrant:6333

# Legacy Milvus configuration (if needed for migration)
# MILVUS_HOST=127.0.0.1
# MILVUS_PORT=19530
# MILVUS_COLLECTION_NAME=knowledge_graph

# =============================================================================
# Search Engine Configuration
# =============================================================================
# SearXNG URL (optional)
# IMPORTANT: When SearXNG is running on the SAME machine as Docker (localhost:8088),
#            Docker containers must use host.docker.internal instead of localhost
#
# For SearXNG running on the Docker host machine (typical setup):
SEARXNG_URL=http://host.docker.internal:8088

# For external SearXNG instance:
# SEARXNG_URL=http://192.168.1.100:8088

# Leave empty to disable web search functionality:
# SEARXNG_URL=

# =============================================================================
# Server Configuration
# =============================================================================
# Agent server port (internal)
AGENT_PORT=5001

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# Network Configuration
# =============================================================================
# These are used by the frontend to connect to the backend
# When accessing from outside Docker, use localhost
VITE_API_URL=http://localhost:3001

# =============================================================================
# Legacy Configuration
# =============================================================================
# Kept for backwards compatibility
LOCAL_TEXTGEN_API_BASE=http://localhost:5000/v1
LOCAL_TEXTGEN_API_KEY=your-api-key-here

# =============================================================================
# Optional: External Service URLs
# =============================================================================
# If you want to use external Qdrant instance instead of containerized one:
# QDRANT_URL=http://your-qdrant-server:6333

# If you want to use hosted LLM API:
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_API_KEY=sk-your-actual-api-key-here
# LLM_API_BASE=https://api.openai.com/v1
# LLM_API_KEY=sk-your-actual-api-key-here

# =============================================================================
# Development Mode Settings
# =============================================================================
# Uncomment these for development with hot-reload
# NODE_ENV=development
# PYTHONUNBUFFERED=1
# PYTHONDONTWRITEBYTECODE=1
