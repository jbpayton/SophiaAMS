"""
Minimal FastAPI server for the first-run setup wizard.

Runs on AGENT_PORT (default 5001) during setup mode, providing endpoints
for the web wizard to validate connections and save configuration.
"""

import logging
import os
import shutil

import yaml
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional

from personality_presets import get_preset, list_presets, PRESETS

logger = logging.getLogger(__name__)

app = FastAPI(title="SophiaAMS Setup Wizard")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

SETUP_SENTINEL = os.path.join(os.path.dirname(__file__), ".setup_complete")
ROOT_DIR = os.path.dirname(__file__)


# ---------------------------------------------------------------------------
# Models
# ---------------------------------------------------------------------------

class LLMValidateRequest(BaseModel):
    base_url: str
    api_key: str = "not-needed"
    model: str = ""


class EmbeddingValidateRequest(BaseModel):
    model_name: str = "sentence-transformers/all-MiniLM-L6-v2"


class SetupCompleteRequest(BaseModel):
    # Identity
    agent_name: str = "Sophia"
    user_name: str = "User"

    # LLM
    llm_base_url: str = "http://localhost:1234/v1"
    llm_api_key: str = "not-needed"
    llm_model: str = ""
    llm_max_tokens: int = 16000
    llm_context_window: int = 16384

    # Personality
    personality_preset: str = "magician"
    custom_personality: str = ""

    # Optional integrations
    telegram_token: str = ""
    searxng_url: str = ""


# ---------------------------------------------------------------------------
# Endpoints
# ---------------------------------------------------------------------------

@app.get("/api/setup/status")
def setup_status():
    return {"setup_complete": os.path.exists(SETUP_SENTINEL)}


@app.get("/api/setup/presets")
def get_presets():
    return {"presets": list_presets()}


@app.post("/api/setup/validate-llm")
async def validate_llm(req: LLMValidateRequest):
    """Test LLM connection by sending a simple prompt."""
    try:
        import httpx

        url = req.base_url.rstrip("/") + "/chat/completions"
        payload = {
            "messages": [{"role": "user", "content": "Say hello in one word."}],
            "max_tokens": 32,
        }
        if req.model:
            payload["model"] = req.model

        headers = {"Content-Type": "application/json"}
        if req.api_key and req.api_key != "not-needed":
            headers["Authorization"] = f"Bearer {req.api_key}"

        async with httpx.AsyncClient(timeout=15.0) as client:
            resp = await client.post(url, json=payload, headers=headers)
            resp.raise_for_status()
            data = resp.json()

        # Try to extract the model's reply
        reply = ""
        if "choices" in data and data["choices"]:
            reply = data["choices"][0].get("message", {}).get("content", "")

        # Try to list available models
        models = []
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                models_resp = await client.get(
                    req.base_url.rstrip("/") + "/models",
                    headers=headers,
                )
                if models_resp.status_code == 200:
                    models_data = models_resp.json()
                    models = [
                        m.get("id", "") for m in models_data.get("data", [])
                    ]
        except Exception:
            pass

        return {
            "success": True,
            "reply": reply.strip(),
            "models": models,
        }

    except Exception as e:
        return {"success": False, "error": str(e), "models": []}


@app.post("/api/setup/validate-embedding")
async def validate_embedding(req: EmbeddingValidateRequest):
    """Test that the embedding model can load."""
    try:
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer(req.model_name)
        vec = model.encode(["test"])
        dim = len(vec[0])
        return {"success": True, "dimension": dim}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.post("/api/setup/complete")
def complete_setup(req: SetupCompleteRequest):
    """Write .env, update sophia_config.yaml, write persona_template.txt, create sentinel."""
    try:
        # 1. Write .env
        env_lines = [
            "# SophiaAMS Configuration (generated by setup wizard)",
            "",
            "# LLM",
            f"LLM_API_BASE={req.llm_base_url}",
            f"LLM_API_KEY={req.llm_api_key}",
            f"LLM_MODEL={req.llm_model}",
            f"LLM_MAX_TOKENS={req.llm_max_tokens}",
            f"LLM_CHAT_MAX_TOKENS={min(req.llm_max_tokens, req.llm_context_window // 2 + 2048)}",
            f"LLM_CONTEXT_WINDOW={req.llm_context_window}",
            f"EXTRACTION_MODEL={req.llm_model}",
            f"EXTRACTION_MAX_TOKENS={req.llm_max_tokens}",
            "",
            "# Embedding",
            "EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2",
            "EMBEDDING_DIM=384",
            "",
            "# Server",
            f"AGENT_PORT={os.getenv('AGENT_PORT', '5001')}",
            "",
            "# Identity",
            f"AGENT_NAME={req.agent_name}",
            f"USER_NAME={req.user_name}",
            "",
            "# Agent Settings",
            "AGENT_TEMPERATURE=0.7",
            "WORKSPACE_PATH=./workspace",
            "SKILLS_PATH=./skills",
            "",
            "# Memory",
            "MEMORY_DATA_PATH=./data",
            "VECTOR_DB_PATH=./VectorKnowledgeGraphData",
            "STREAM_MONITOR_IDLE_SECONDS=30",
            "AUTO_RECALL_LIMIT=10",
            "",
            "# Optional integrations",
            f"SEARXNG_URL={req.searxng_url}",
            f"TELEGRAM_BOT_TOKEN={req.telegram_token}",
            "",
            "SOPHIA_CONFIG_PATH=./sophia_config.yaml",
        ]
        env_path = os.path.join(ROOT_DIR, ".env")
        with open(env_path, "w", encoding="utf-8") as f:
            f.write("\n".join(env_lines) + "\n")
        logger.info(f"Wrote {env_path}")

        # 2. Update sophia_config.yaml
        config = {
            "agent": {
                "name": req.agent_name,
                "user_name": req.user_name,
                "rate_limit_per_hour": 120,
            },
            "event_sources": {
                "webui": {"enabled": True},
                "telegram": {
                    "enabled": bool(req.telegram_token),
                    "token": req.telegram_token or "${TELEGRAM_BOT_TOKEN}",
                    "allowed_chat_ids": [],
                },
                "scheduler": {
                    "enabled": True,
                    "jobs": [
                        {
                            "id": "goal_check",
                            "prompt": "Check your active goals. Update progress on any that you can.",
                            "interval_seconds": 3600,
                        }
                    ],
                },
                "goal_engine": {
                    "enabled": True,
                    "cooldown_seconds": 30,
                    "max_consecutive_goals": 10,
                    "rest_seconds": 300,
                },
            },
        }
        config_path = os.path.join(ROOT_DIR, "sophia_config.yaml")
        with open(config_path, "w", encoding="utf-8") as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)
        logger.info(f"Wrote {config_path}")

        # 3. Write persona_template.txt with chosen personality
        preset = get_preset(req.personality_preset)
        if req.personality_preset.lower() == "custom" and req.custom_personality:
            personality_block = req.custom_personality
        else:
            personality_block = preset["system_prompt_snippet"]

        template_path = os.path.join(ROOT_DIR, "persona_template.txt")
        # Read the default template, fill in the personality block
        default_template_path = os.path.join(ROOT_DIR, "persona_template.txt")
        if os.path.exists(default_template_path):
            with open(default_template_path, "r", encoding="utf-8") as f:
                template = f.read()
        else:
            template = _default_template()

        # Replace the {personality_block} placeholder with actual personality
        filled = template.replace("{personality_block}", personality_block)
        # Also fill in names so the template is ready
        filled = filled.replace("{agent_name}", req.agent_name)
        filled = filled.replace("{user_name}", req.user_name)

        with open(template_path, "w", encoding="utf-8") as f:
            f.write(filled)
        logger.info(f"Wrote {template_path}")

        # 4. Create sentinel
        with open(SETUP_SENTINEL, "w") as f:
            f.write("setup completed\n")
        logger.info(f"Created {SETUP_SENTINEL}")

        return {"success": True, "message": "Setup complete! Restart SophiaAMS to begin."}

    except Exception as e:
        logger.exception("Setup completion failed")
        return {"success": False, "error": str(e)}


# ---------------------------------------------------------------------------
# Health (so the Node.js proxy can check we're alive)
# ---------------------------------------------------------------------------

@app.get("/health")
def health():
    return {"status": "setup_mode", "setup_complete": os.path.exists(SETUP_SENTINEL)}


def _default_template() -> str:
    """Fallback template if persona_template.txt doesn't exist yet."""
    return (
        "You are {agent_name}. You are a highly advanced AI assistant.\n\n"
        "Current time: {current_time}\n\n"
        "{personality_block}\n\n"
        "{skills_section}\n"
    )
